\chapter{Tangible User Interfaces}
\label{chp:tangibleinterfaces}

This chapter will introduce the reader to \emph{tangible user interfaces}, and elaborate on some existing research that has been done on the concept. In addition the chapter will describe the methods we used to develop our tangible user interface.   

\section{About Tangible User Interfaces}
\label{sec:abouttuis}

In 1997, Ishii et. al. presented an article called ``Tangible Bits: Towards Seamless Interfaces between People, Bits and Atoms'' \cite{ishii1997tangible}. They established the term ``Tangible User Interface'' (TUI) as a way to move beyond the dominant model of Graphical User Interfaces (GUI). 
While GUIs show information (bits) in the form of pixels mapped to a display, Ishii meant that TUIs would represent the bits in form of physical objects. The objective of TUIs was explained as to \emph{augment the real physical world by coupling digital information to everyday physical objects and environments}\cite{ishii1997tangible}. 

``Urp''\cite{underkoffler1999urp} is an example of an first-generation TUI. Urp is a workbench used by architects in order to determine shadow patterns for models of buildings. By moving a ``clock tool'' the lighting on the workbench would move according to what time of day was choosen. Instead of interacting with the lights directly, the TUI factor of the workbench was the clock tool.
What made this a first-generation TUI are the fairly simple and state-determined operations.

``Sandscape''\cite{ishii2004bringing} is an example of a second-generation TUI. Sandscape uses clay, sand, cameras, digital software and lighting to give an overview of a Geographical Information System(GIS). The users could interact with the clay, forming dunes or dig holes and the software would calculate landscape analysis based on the interaction. Sandscape is dynamical user interface since it may change to several different non-predefined states. Systems such as this are called ``continuous TUIs''.

In 2008, Xie et. al. performed a study on how children reacted using different interfaces in order to solve a jigsaw puzzle\cite{xie2008tangibles}. The different interfaces were a physical interface (i.e. a standard jigsaw puzzle), a TUI and a GUI. Their main finding was that children enjoyed playing with the different interfaces equally. However, the children were more likely to start a puzzle over again if the interface were physical or tangible, which implies that a repeated task is more likely to be performed if the children are playing with a tangible or physical interface, while it becomes boring to do the same task over and over again on a graphical user interface. As a disclaimer it is worth mentioning that the puzzles were being solved by groups of two, and considering the GUI was a computer with one mouse, the children did not get the same sharing experience as with the other interfaces. 


\section{Examples of Use}
\label{sec:tuiexamples}
Using TUIs instead of GUIs has been proven to work in several different settings. In this section, we will give an overview on some of the domains in which the concept has been proven to work. 

\textbf{Learning} 

Terrenghi \etal{} designed a cube for learning, giving children quizzes where answers had the shape of text or images\cite{terrenghi2006cube}. Children could then rotate the cube in order to get the correct answer pointing upwards, like a dice. They concluded that the TUI gave children a different set of affordances that prompted a great initial engagement\cite{terrenghi2006cube}. 

\textbf{Information Sharing} 

Hinckley et. al. created a tangible user interface for neurosurgical vizualisation\cite{hinckley1994passive}. Their tool proved helpful for neurosurgeons to provide physical familiar tools that could display information digitally. Their tool showed possibilities for creating and viewing cutting planes and planning neurosurgery. Their tool made it easier for them to display the surgical cutting planes to other surgeons, or to persons with less knowledge in neurosurgery. 

Moran et. al. designed a physical wall for sharing information on people in an office\cite{moran1999design}. The system, named ``Collaborage'' showed a person locator and different types of project information. Collaborage showed how the use of traditional use of walls and sticky notes translated into a digital software in a positive manner.


\textbf{Collaborative Learning} 

Scarlatos et. al. created a system called TICLE (Tangible Interface in Collaborative Learning), which were used to help children solve a Tangram\cite{scarlatos1999ticle}. Their system consisted of the tangram pieces and a surface to place them on. The tangram pieces had a tracker on them, which was used to guide children when placed a piece in the wrong place. Once the solution had been found, the children were able to explain the underlying geometric principles behind their solution.   

\textbf{Interactive Storytelling} 

Zhou et. al. designed a cube for storytelling, using a head mounted display and a ``magic story cube'' in order to let children explore the world while being told a story\cite{zhou2004magic}. Stanton et. al. created a ``magic carpet'', giving children possiblity to influence a story in the classroom\cite{stanton2001classroom}. 

\textbf{Social Context} 

The ``Marble Answering Machine'' is an invention by Durrell Bishop, dating back to 1992\cite{crampton1995hand}. The interface allows users to drop marbles into a play-back indent on the system, which plays a recorded message. Similarly, Karotz is able to read your Twitter feed if the Twitter application for Karotz had been installed\fnurl{Twitter application for Karotz}{http://tiny.cc/karotztwitter}.   


\section{TUIs Used in Health Care}
\label{sec:effectofrobots}
In 2003, Wada et. al. conducted a study on how the introduction of robotics affected the elderly\cite{wada2004effects}. They carried out their research at a day service center in Japan, where they placed a robotic seal, named Paro, together with the elderly. It had recently been found that animals have a positive effects on blood preassure, depression and loneliness. They placed a robotic seal in the care center, and analyzed the reactions from the elderly. 

The results showed that the elderly were in a better mood after interacting with Paro over five weeks, and became worse once Paro was removed. In addition, nurses' burnout rate decreased during the experiment, which implied that they had easier days when Paro was there. The study showed that the elderly's quality of life improved after Paro was introduced.           

Farr \etal{} did a study on children with Autisitic Spectrum Condition (ACS), when playing with a TUI called Topobo\fnurl{Topobo}{http://www.topobo.com/}\cite{farr2010social}. The study compared the level of social interaction when playing with Topobo, compared to playing with LEGO. Their findings showed that ACS children were playing more cooperatively with the TUI than LEGO. Additionally, children with traditional development were able to play more cooperative, solitary and parallell when using a TUI, suggesting that 

\textit{``(\ldots) programmable digital technology may support more pathways to social interaction.''}

\section{Tangible User Interface Paradigms}
Ullmer states that a tangible user interface should embody the following four properties\cite{ullmer2002tangible}:

\begin{enumerate}
	\item{Physically Embodied}
	\item{Physically Representational}
	\item{Physically Manipulable}
	\item{Spatially Reconfigurable}
\end{enumerate}

Ullmer further states that these four properties describe physical artifacts as representations and controls for digital information. 

Ullmer proposes three different paradigms of tangible interfaces; \emph{Token and Constraints}, \emph{Interactive Surfaces}, and \emph{Constructive Assemblies}. These classes are partly based on varying degree of support for continuous and discrete forms of interaction\cite{ullmer2002tangible}.

\subsection{Token + Constraint Approach}
\label{sec:tokenandconstraint}
The ``Token + Constraint'' approach centers on a hierarchical relationship between tokens and constraints. Tokens may be placed within or removed from the compatible constraints. The physical shape of the tokens and constraints display whether or not the tokens are compatible or not. This approach support a combination of continuous and discrete interactions.

A system that is capable of reading RFID-tags is considered a Token + Constraint system. The RFID-tag is considered a token, while the area the RFID scanner can read from is considered as a constraint.  




\textbf{Strenghts of Token + Constraint approach}

Ullmer states that interpretive constraints will help to express which of the physical tokens can take part within a given interpretive constraint, which physical configurations these physical tokens can take and the demarcation between interaction regions with different computational interpretation.

These interpretive constraints may help to simplify the human perception since humans are good at comparing shapes and forms. 
It may help human manipulation since interpretive constraints provide an increased sense of kinesthetic feedback from the manipulation of tokens. 

\subsection{Interactive Surfaces}
\label{sec:interactivesurfaces}
In this paradigm, users manipulate physical objects upon an augmented planar surface \cite{ullmer2002tangible}. These objects are then tracked, interpreted and graphically mediated through the surface. A popular usage of interactive surfaces is to create interactive workbenches, where objects are configured upon a horizontal workbench. For instance, metaDESK with the Tangible Geospace application, had a large map of a city as it's workbench \cite{ullmer1997metadesk}. Combined with magnifying glass, it allowed users to look at 3D models of particular places in a town. 



\subsection{Constructive Assemblies}
\label{sec:constructiveassemblies}
One major approach for tangible interfaces draws inspiration from buildings blocks and LEGO\texttrademark. Such ``constructive assemblies'' of modular, interconnecting elements have been used for modeling real life buildings \cite{aish1984architecture}, and geometric modeling of all kind of shapes\cite{anderson2000tangible}. Constructive assemblies give an easy-to-use and highly tangible representation of digital information. 

While there were possibilities for how to use constructive assemblies for developing a tangible user interface to help children with asthma, we decided to not use this paradigm in the construction of AsthmaBuddy. The use of small parts that can easily be lost was not a solution we saw fit for our age group of 3 - 7 year-olds.


\section{Developing Tangible User Interfaces}
\label{sec:developingtangibleinterfaces}

\subsection{Champoux's Development Framework}
\label{sec:champoux}
Much research has been performed regarding the potential benefits of TUI's, but there are few guidelines on how to actually create a TUI. Champoux proposes a mechanism to design TUI's based achieving fitness between the form and its context\cite{champoux2007design}.
He proposes three classes of questions, which corresponds to the different development phases of TUIs:
\begin{itemize}
  \item Defining the boundaries
  \item Orienting the components
  \item Fitting the components
\end{itemize} 


Answering the questions in Table \ref{tab:tuidesign}, will make the development phase easier.   


\begin{table}[h]
	\begin{tabular}{| p{5.0cm} | p{5.0cm} | p{5.0cm} |}
	\hline
	\textbf{Defining the Boundaries} & \textbf{Orienting the Concepts} & \textbf{Fitting the Components} \\
	\hline
	\textbf{BO1}: What should the user experience? \newline
	\textbf{BO2}: What are the human tasks? \newline
	\textbf{BO3}: What would the artefact represent and control? \newline 
	\textbf{BO4}: What are the conventions? \newline 
	&
	\textbf{OC5a}: What is the nature of the interaction for each sub task? (Continuous vs Discrete vs Assembly) \newline
	\textbf{OC5b}: What are the electromechanical and physical ergonomic constraints for this task? \newline
	\textbf{OC6}: Does the sub-task need any relational interaction? \newline
	&
	\textbf{FC7}: What are the relations between the objects and the actions? \newline 
	\textbf{FC8}: What is the task order when using the artefact? \\ 
	\hline
	
	\end{tabular}
	\caption{The eight questions stated by Champoux\cite{champoux2007design}}
	\label{tab:tuidesign}
\end{table}  

We considered Question \textbf{OC5b} as irrelevant for our purposes, as we developed a stationary artefact without any electromechanical and phyical ergonomic properties, i.e. no moving arms, waving ears, etc. As far as questions \textbf{FC7} and \textbf{FC8} go, we considered these irrelevant. These questions assume that the tangible interface performs a task for the user, which is not a part of our system. The remaining questions were considered relevant, and will be discussed in Section \ref{sec:answeringchampoux}.     

\input{Chapters/tangible-interfaces/ubiquity.tex}

\section{Summary}
\label{sec:tangiblesummary}
Tangible user interfaces are about representing digital information through physical objects. There are a lot of examples on tangible user interfaces, and we have taken a brief look into some of them (see \ref{sec:tuiexamples}). There seems to be a lot of activity going on in this field of research. However, only a few are commercially available. 

Champoux proposed a design mechanism to create tangible interfaces. The design mechanism is somewhat abstract, and lacks obvious issues such as how to actually display information to a user, which Bellotti \etal{} (see \ref{sec:challenges-with-TUI}) expose as a challenge with creating ubiquitous systems and TUI's. We used Champoux' approach to a certain extent, and kept Bellotti's challenges in mind when designing \buddy{}.   

When developing \ab{}, we continually looked for ways AsthmaBuddy could be of use for the asthmatic children. Our main focus was helping children to remember and apply the treatment correctly. Additionally, we continued to look for other ways AsthmaBuddy may be of help for the children or their parents throughout the project.  

 